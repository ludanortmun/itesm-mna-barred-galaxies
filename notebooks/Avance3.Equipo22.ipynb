{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Detección de barras en galaxias - Modelo \"Baseline\"\n",
    "## Proyecto integrador MNA\n",
    "\n",
    "### Integrantes\n",
    "- Jonathan Jesús Marmolejo Hernández - A01795195\n",
    "- Isaid Posadas Oropeza - A01795015\n",
    "- Luis Daniel Ortega Muñoz - A01795197"
   ],
   "id": "83c1172cf0612932"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Uncomment this if running in Google Colab. It will install the bargal package from GitHub.\n",
    "# !pip install git+https://github.com/ludanortmun/itesm-mna-barred-galaxies.git"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importando librerías",
   "id": "376059bc1092e695"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from bargal.dataset.load import load_dataset"
   ],
   "id": "4dff0f7f031c36a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ],
   "id": "7d0725ae9d82b13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparando el conjunto de datos",
   "id": "a2fa3000020d032"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El primer paso consiste en cargar nuestro conjunto de datos y dividirlo en conjunto de entrenamiento, validación y prueba.",
   "id": "66b99aa26d93734f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_path = '../data/dataset.csv'\n",
    "\n",
    "df = load_dataset(dataset_path)\n",
    "\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['Bars'])\n",
    "valid_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42, stratify=val_test_df['Bars'])\n",
    "\n",
    "print(f'Train size: {len(train_df)}')\n",
    "print(f'Validation size: {len(valid_df)}')\n",
    "print(f'Test size: {len(test_df)}')"
   ],
   "id": "676bd3ff6a6b1a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora creamos nuestra clase para representar el conjunto de datos, heredando de Dataset de PyTorch. El dataset a utilizar para nuestra red neuronal consiste en imágenes de galaxias y su respectiva etiqueta, que indica si la galaxia tiene o no una barra.\n",
    "\n",
    "La etiqueta es un tensor de tamaño 1, donde 1 indica que la galaxia tiene una barra y 0 indica que no. Sin embargo, el conjunto de datos original no tiene etiquetas binarias, sino múltiples categorías indicando el tipo de barra que tiene la galaxia. Por lo tanto, convertimos cualquier etiqueta que represente la presencia de una barra (independientemente de sus características) a 1 y cualquier etiqueta que represente la ausencia de una barra a 0. También debemos filtrar elementos con la etiqueta -0.5, la cual simboliza que la categoria de la galaxia es desconocida. Estas transformaciones fueron exploradas previamente en el entregable [Avance1.Equipo22.ipynb](https://github.com/ludanortmun/itesm-mna-barred-galaxies/tree/main/notebooks/Avance1.Equipo22.ipynb), donde se creó la columna `has_bar` derivada de `Bars` y se filtraron los elementos sin clasificación.\n",
    "\n",
    "En cuanto a la carga de imágenes, este conjunto de datos consiste en las imágenes de galaxias previamente procesadas en formato PNG. El preprocesamiento consiste, principalmente, en la sustracción de las bandas G y R para enfatizar las estructuras de barras. Las imágenes resultantes tienen dimensiones de 400x400 píxeles y están en escala de grises. Estas imágenes son cargadas utilizando la librería PIL y convertidas a tensores.\n",
    "\n",
    "El script de preprocesamiento puede ser consultado en este enlace: [bargal/commands/preprocess.py](https://github.com/ludanortmun/itesm-mna-barred-galaxies/blob/297f69b278ea6bc5099ef23a0d539602995bc55e/bargal/commands/preprocess.py)\n",
    "\n",
    "El conjunto de imágenes pre procesadas puede descargarse con el siguiente enlace: [dataset.processed.GRLogDiff](https://tecmx-my.sharepoint.com/:u:/g/personal/a01795197_tec_mx/EexaLnqaLLdCt1JNxLib8VYBeOHJo95vuOr-Pfxv-55Iww?e=0gfeuq)\n"
   ],
   "id": "aacb0a3cc0f666c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class GalaxiesDataset(Dataset):\n",
    "    def __init__(self, galaxies_df: pd.DataFrame, img_dir: str):\n",
    "        self.filtered_df = galaxies_df[galaxies_df['Bars'] >= 0].reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.filtered_df.iloc[idx]\n",
    "        label = 1.0 if row['Bars'] != 0 else 0.0\n",
    "        img_path = f\"{self.img_dir}/{row['name']}.png\"\n",
    "\n",
    "        # Load image and convert to tensor\n",
    "        with Image.open(img_path) as img:\n",
    "            image = transforms.ToTensor()(img)\n",
    "\n",
    "        return image.to(device), torch.tensor([label], dtype=torch.float32).to(device)"
   ],
   "id": "4b5dc98dcd9ba6bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n = 8\n",
    "processed_images_path = '../data/processed'\n",
    "\n",
    "train_data = GalaxiesDataset(train_df, processed_images_path)\n",
    "train_loader = DataLoader(train_data, batch_size=n, shuffle=True)\n",
    "train_N = len(train_loader.dataset)\n",
    "\n",
    "valid_data = GalaxiesDataset(valid_df, processed_images_path)\n",
    "valid_loader = DataLoader(valid_data, batch_size=n)\n",
    "valid_N = len(valid_loader.dataset)"
   ],
   "id": "30ccf95a090ad809",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definiendo el modelo",
   "id": "c204fa8ca4c12f96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Debido a que estamos trabajando con imágenes, utilizaremos una red neuronal convolucional (CNN) como modelo base. La arquitectura de la red es la siguiente:",
   "id": "da2467289a9b28a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: define the model architecture\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # First conv layer\n",
    "    nn.Conv2d(1, 32, kernel_size=3, padding=1), # 32 x 400 x 400\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # 32 x 200 x 200\n",
    "\n",
    "    # Second conv layer\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1), # 64 x 200 x 200\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # 64 x 100 x 100\n",
    "\n",
    "    # Third conv layer\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1), # 128 x 100 x 100\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), # 128 x 50 x 50\n",
    "\n",
    "    ## Flattening\n",
    "    nn.Flatten(),\n",
    "\n",
    "    # Fully connected layers\n",
    "    nn.Linear(128 * 50 * 50, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.5),\n",
    "\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.5),\n",
    "\n",
    "    nn.Linear(256, 1)\n",
    ")"
   ],
   "id": "ed3b52a96da0ac0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = torch.compile(model.to(device))\n",
    "model"
   ],
   "id": "c4ff2f951be42f25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Función de pérdida y optimizador\n",
    "\n",
    "Debido a que estamos trabajando con un problema de clasificación binaria, utilizaremos la función de pérdida `BCEWithLogitsLoss`. El optimizador a utilizar es Adam."
   ],
   "id": "7986c1f3e4b1418b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "my_model = model.to(device)"
   ],
   "id": "f4eff48e997b3f8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento",
   "id": "da8deb17900a2345"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Definiendo la función de entrenamiento",
   "id": "fd133f03e7b51a0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    zero_tensor = torch.tensor([0]).to(device)\n",
    "    pred = torch.gt(output, zero_tensor)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ],
   "id": "b034f47b9836c7cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train() -> tuple[float, float]:\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "\n",
    "    return loss, accuracy"
   ],
   "id": "b94362a1333e42b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def validate() -> tuple[float, float]:\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "\n",
    "    return loss, accuracy"
   ],
   "id": "2795ba41d0f55b2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ejecución del entrenamiento",
   "id": "560728de38354e39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "prev_loss = float('inf')\n",
    "min_delta = 0.001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train()\n",
    "    valid_loss, valid_acc = validate()\n",
    "    print(f'Epoch {epoch}: Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | Valid Loss={valid_loss:.4f}, Acc={valid_acc:.4f}')\n",
    "\n",
    "    if abs(prev_loss - valid_loss) < min_delta:\n",
    "        print('Stopping early')"
   ],
   "id": "1d67a8475287287",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Guardando el modelo",
   "id": "1a8d8e28e2cc178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_path = '../models/model.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ],
   "id": "58e18d1f00f1df48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluación del modelo",
   "id": "ca41fcf5cf7413e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Una vez entrenada la red neuronal, procedemos a evaluar su desempeño en el conjunto de prueba.",
   "id": "f0f5452ad751c2a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: Using the train dataset, compute classification report, confusion matrix, etc.",
   "id": "450f94b461ec6a57",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
